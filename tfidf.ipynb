{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = pd.read_csv('cleaned_dataset.csv')\n",
    "sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_file.text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_weighting = final_file.copy()\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(file_weighting.text.values.astype('U'))\n",
    "features = pd.Series(tfidf.get_feature_names_out())\n",
    "transformed = tfidf.transform(file_weighting.text.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], str(x.text).lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.text]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.070661800630579, 1.4898866718974308, 0.9786...</td>\n",
       "      <td>[5.996326430329564, 6.992819837437327, 1.55530...</td>\n",
       "      <td>twitter prior musk takeover talking directly n...</td>\n",
       "      <td>351.171740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.171212606414365, 1.6110511295479415, 1.6746...</td>\n",
       "      <td>[11.299875938505501, 7.9656217550533075, 8.216...</td>\n",
       "      <td>article say imply states feature turns crashes...</td>\n",
       "      <td>524.379199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.9540358009457152, 0.9786753693078538, 1.77...</td>\n",
       "      <td>[7.512398252312913, 1.555309033361735, 9.53835...</td>\n",
       "      <td>og musk duck lives wall</td>\n",
       "      <td>29.696213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3.883288813006564, 1.6448545388112097, 1.3164...</td>\n",
       "      <td>[10.07734760977445, 3.7509426108737416, 4.8348...</td>\n",
       "      <td>dare_speak way great powerful musk obviously d...</td>\n",
       "      <td>112.723930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.696641513583642, 1.339973693457616, 1.64246...</td>\n",
       "      <td>[7.398284945545492, 6.0046645443335285, 6.9052...</td>\n",
       "      <td>cannot_wait finally excuse shower douche</td>\n",
       "      <td>54.617788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61277</th>\n",
       "      <td>[1.3054374751824371, 3.3744355009374853, 1.385...</td>\n",
       "      <td>[2.708287137775497, 9.458308401368226, 6.13437...</td>\n",
       "      <td>like brain_dead lmao anything barely relating ...</td>\n",
       "      <td>144.924125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61278</th>\n",
       "      <td>[1.5343300576417465, 4.772229403494811, 1.6039...</td>\n",
       "      <td>[6.638762696040674, 10.636963397709872, 12.599...</td>\n",
       "      <td>lying agenda_please correct errors anything sa...</td>\n",
       "      <td>305.757294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61279</th>\n",
       "      <td>[1.5064479466120888, 1.456652356153979, 1.4127...</td>\n",
       "      <td>[5.071485594430851, 6.432270778318906, 3.24863...</td>\n",
       "      <td>hard disagree think parody elon_musk sure tend...</td>\n",
       "      <td>592.831585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61280</th>\n",
       "      <td>[1.4606167682907296, 1.4127184184664383, 1.655...</td>\n",
       "      <td>[4.8356005947148075, 3.2486355381327656, 4.346...</td>\n",
       "      <td>yeah think many things lining right smaller_sc...</td>\n",
       "      <td>973.381514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61281</th>\n",
       "      <td>[2.543433490104342, 0.9786753693078538, 1.5891...</td>\n",
       "      <td>[9.384200429214504, 1.555309033361735, 6.65728...</td>\n",
       "      <td>good_choice musk impossible regulate level wou...</td>\n",
       "      <td>183.186508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55354 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentiment_coeff  \\\n",
       "0      [1.070661800630579, 1.4898866718974308, 0.9786...   \n",
       "1      [1.171212606414365, 1.6110511295479415, 1.6746...   \n",
       "2      [-0.9540358009457152, 0.9786753693078538, 1.77...   \n",
       "3      [3.883288813006564, 1.6448545388112097, 1.3164...   \n",
       "4      [1.696641513583642, 1.339973693457616, 1.64246...   \n",
       "...                                                  ...   \n",
       "61277  [1.3054374751824371, 3.3744355009374853, 1.385...   \n",
       "61278  [1.5343300576417465, 4.772229403494811, 1.6039...   \n",
       "61279  [1.5064479466120888, 1.456652356153979, 1.4127...   \n",
       "61280  [1.4606167682907296, 1.4127184184664383, 1.655...   \n",
       "61281  [2.543433490104342, 0.9786753693078538, 1.5891...   \n",
       "\n",
       "                                            tfidf_scores  \\\n",
       "0      [5.996326430329564, 6.992819837437327, 1.55530...   \n",
       "1      [11.299875938505501, 7.9656217550533075, 8.216...   \n",
       "2      [7.512398252312913, 1.555309033361735, 9.53835...   \n",
       "3      [10.07734760977445, 3.7509426108737416, 4.8348...   \n",
       "4      [7.398284945545492, 6.0046645443335285, 6.9052...   \n",
       "...                                                  ...   \n",
       "61277  [2.708287137775497, 9.458308401368226, 6.13437...   \n",
       "61278  [6.638762696040674, 10.636963397709872, 12.599...   \n",
       "61279  [5.071485594430851, 6.432270778318906, 3.24863...   \n",
       "61280  [4.8356005947148075, 3.2486355381327656, 4.346...   \n",
       "61281  [9.384200429214504, 1.555309033361735, 6.65728...   \n",
       "\n",
       "                                                sentence  sentiment_rate  \\\n",
       "0      twitter prior musk takeover talking directly n...      351.171740   \n",
       "1      article say imply states feature turns crashes...      524.379199   \n",
       "2                                og musk duck lives wall       29.696213   \n",
       "3      dare_speak way great powerful musk obviously d...      112.723930   \n",
       "4               cannot_wait finally excuse shower douche       54.617788   \n",
       "...                                                  ...             ...   \n",
       "61277  like brain_dead lmao anything barely relating ...      144.924125   \n",
       "61278  lying agenda_please correct errors anything sa...      305.757294   \n",
       "61279  hard disagree think parody elon_musk sure tend...      592.831585   \n",
       "61280  yeah think many things lining right smaller_sc...      973.381514   \n",
       "61281  good_choice musk impossible regulate level wou...      183.186508   \n",
       "\n",
       "       prediction  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "61277           1  \n",
       "61278           1  \n",
       "61279           1  \n",
       "61280           1  \n",
       "61281           1  \n",
       "\n",
       "[55354 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df[replacement_df['prediction'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
