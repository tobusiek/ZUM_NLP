{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from re import sub\n",
    "from time import time \n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ['twitter', 'prior', 'musk', 'takeover', 'talk...\n",
       "1        ['article', 'ay', 'imply', 'tates', 'feature',...\n",
       "2          ['og', 'musk', 'would', 'uck', 'lives', 'wall']\n",
       "3        ['would', 'are', 'peak', 'way', 'great', 'powe...\n",
       "4        ['cannot', 'wait', 'finally', 'excuse', 'hower...\n",
       "                               ...                        \n",
       "61285    ['like', 'brain', 'would', 'ead', 'piranhas', ...\n",
       "61286    ['lying', 'agenda', 'please', 'correct', 'erro...\n",
       "61287    ['hard', 'would', 'isagree', 'think', 'parody'...\n",
       "61288    ['yeah', 'think', 'many', 'things', 'lining', ...\n",
       "61289    ['good', 'choice', 'musk', 'impossible', 'are'...\n",
       "Name: text, Length: 61290, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_model = pd.read_csv('musk_clean.csv')\n",
    "sentences = file_model.text\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:29:49: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2023-05-20T14:29:49.884169', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'created'}\n",
      "INFO - 14:29:49: collecting all words and their counts\n",
      "WARNING - 14:29:49: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "INFO - 14:29:49: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:29:50: PROGRESS: at sentence #50000, processed 19589894 words, keeping 75 word types\n",
      "INFO - 14:29:51: collected 75 word types from a corpus of 24174807 raw words and 61290 sentences\n",
      "INFO - 14:29:51: Creating a fresh vocabulary\n",
      "INFO - 14:29:51: Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 72 unique words (96.00% of original 75, drops 3)', 'datetime': '2023-05-20T14:29:51.068284', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 14:29:51: Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 24174802 word corpus (100.00% of original 24174807, drops 5)', 'datetime': '2023-05-20T14:29:51.068543', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 14:29:51: deleting the raw counts dictionary of 75 items\n",
      "INFO - 14:29:51: sample=1e-05 downsamples 47 most-common words\n",
      "INFO - 14:29:51: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 398538.2770101533 word corpus (1.6%% of prior 24174802)', 'datetime': '2023-05-20T14:29:51.069496', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 14:29:51: estimated required memory for 72 words and 300 dimensions: 208800 bytes\n",
      "INFO - 14:29:51: resetting layer weights\n",
      "INFO - 14:29:51: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-05-20T14:29:51.071021', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:52:36: Word2Vec lifecycle event {'msg': 'training model with 7 workers on 72 vocabulary and 300 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4 shrink_windows=True', 'datetime': '2023-05-20T14:52:36.240795', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'train'}\n",
      "INFO - 14:52:37: EPOCH 0 - PROGRESS: at 56.87% examples, 226994 words/s, in_qsize 2, out_qsize 3\n",
      "INFO - 14:52:37: EPOCH 0: training on 24174807 raw words (398029 effective words) took 1.7s, 228544 effective words/s\n",
      "INFO - 14:52:38: EPOCH 1 - PROGRESS: at 57.12% examples, 227500 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:52:39: EPOCH 1: training on 24174807 raw words (398958 effective words) took 1.7s, 230334 effective words/s\n",
      "INFO - 14:52:40: EPOCH 2 - PROGRESS: at 57.40% examples, 228539 words/s, in_qsize 2, out_qsize 3\n",
      "INFO - 14:52:41: EPOCH 2: training on 24174807 raw words (397715 effective words) took 1.7s, 229743 effective words/s\n",
      "INFO - 14:52:42: EPOCH 3 - PROGRESS: at 56.81% examples, 225657 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:52:43: EPOCH 3: training on 24174807 raw words (397930 effective words) took 1.7s, 228785 effective words/s\n",
      "INFO - 14:52:44: EPOCH 4 - PROGRESS: at 57.32% examples, 228666 words/s, in_qsize 4, out_qsize 3\n",
      "INFO - 14:52:44: EPOCH 4: training on 24174807 raw words (398079 effective words) took 1.7s, 229961 effective words/s\n",
      "INFO - 14:52:45: EPOCH 5 - PROGRESS: at 56.41% examples, 224980 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:52:46: EPOCH 5: training on 24174807 raw words (397888 effective words) took 1.7s, 227612 effective words/s\n",
      "INFO - 14:52:47: EPOCH 6 - PROGRESS: at 57.07% examples, 227433 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:52:48: EPOCH 6: training on 24174807 raw words (398465 effective words) took 1.7s, 230101 effective words/s\n",
      "INFO - 14:52:49: EPOCH 7 - PROGRESS: at 56.18% examples, 223785 words/s, in_qsize 14, out_qsize 10\n",
      "INFO - 14:52:50: EPOCH 7: training on 24174807 raw words (398950 effective words) took 1.7s, 228090 effective words/s\n",
      "INFO - 14:52:51: EPOCH 8 - PROGRESS: at 56.77% examples, 226969 words/s, in_qsize 14, out_qsize 7\n",
      "INFO - 14:52:51: EPOCH 8: training on 24174807 raw words (399229 effective words) took 1.7s, 229619 effective words/s\n",
      "INFO - 14:52:52: EPOCH 9 - PROGRESS: at 56.73% examples, 224931 words/s, in_qsize 9, out_qsize 12\n",
      "INFO - 14:52:53: EPOCH 9: training on 24174807 raw words (397726 effective words) took 1.7s, 228042 effective words/s\n",
      "INFO - 14:52:54: EPOCH 10 - PROGRESS: at 56.82% examples, 227633 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:52:55: EPOCH 10: training on 24174807 raw words (399548 effective words) took 1.7s, 230281 effective words/s\n",
      "INFO - 14:52:56: EPOCH 11 - PROGRESS: at 57.11% examples, 227472 words/s, in_qsize 6, out_qsize 3\n",
      "INFO - 14:52:57: EPOCH 11: training on 24174807 raw words (399258 effective words) took 1.8s, 226112 effective words/s\n",
      "INFO - 14:52:58: EPOCH 12 - PROGRESS: at 56.29% examples, 224623 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:52:58: EPOCH 12: training on 24174807 raw words (398837 effective words) took 1.8s, 227603 effective words/s\n",
      "INFO - 14:52:59: EPOCH 13 - PROGRESS: at 56.55% examples, 225250 words/s, in_qsize 14, out_qsize 9\n",
      "INFO - 14:53:00: EPOCH 13: training on 24174807 raw words (398682 effective words) took 1.7s, 228359 effective words/s\n",
      "INFO - 14:53:01: EPOCH 14 - PROGRESS: at 56.99% examples, 227853 words/s, in_qsize 9, out_qsize 11\n",
      "INFO - 14:53:02: EPOCH 14: training on 24174807 raw words (399396 effective words) took 1.7s, 230541 effective words/s\n",
      "INFO - 14:53:03: EPOCH 15 - PROGRESS: at 50.79% examples, 205206 words/s, in_qsize 4, out_qsize 3\n",
      "INFO - 14:53:04: EPOCH 15: training on 24174807 raw words (398616 effective words) took 1.9s, 215195 effective words/s\n",
      "INFO - 14:53:05: EPOCH 16 - PROGRESS: at 55.55% examples, 222039 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:06: EPOCH 16: training on 24174807 raw words (397892 effective words) took 1.8s, 223732 effective words/s\n",
      "INFO - 14:53:07: EPOCH 17 - PROGRESS: at 56.52% examples, 225312 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:07: EPOCH 17: training on 24174807 raw words (397771 effective words) took 1.8s, 226944 effective words/s\n",
      "INFO - 14:53:08: EPOCH 18 - PROGRESS: at 57.11% examples, 226530 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:09: EPOCH 18: training on 24174807 raw words (398028 effective words) took 1.7s, 229474 effective words/s\n",
      "INFO - 14:53:10: EPOCH 19 - PROGRESS: at 54.17% examples, 216218 words/s, in_qsize 14, out_qsize 5\n",
      "INFO - 14:53:11: EPOCH 19: training on 24174807 raw words (398275 effective words) took 1.8s, 221494 effective words/s\n",
      "INFO - 14:53:12: EPOCH 20 - PROGRESS: at 56.34% examples, 223599 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:13: EPOCH 20: training on 24174807 raw words (398166 effective words) took 1.8s, 227420 effective words/s\n",
      "INFO - 14:53:14: EPOCH 21 - PROGRESS: at 56.66% examples, 225485 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:14: EPOCH 21: training on 24174807 raw words (398542 effective words) took 1.8s, 227725 effective words/s\n",
      "INFO - 14:53:15: EPOCH 22 - PROGRESS: at 56.29% examples, 224761 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:16: EPOCH 22: training on 24174807 raw words (399107 effective words) took 1.8s, 228017 effective words/s\n",
      "INFO - 14:53:17: EPOCH 23 - PROGRESS: at 57.37% examples, 229316 words/s, in_qsize 5, out_qsize 3\n",
      "INFO - 14:53:18: EPOCH 23: training on 24174807 raw words (399468 effective words) took 1.7s, 230868 effective words/s\n",
      "INFO - 14:53:19: EPOCH 24 - PROGRESS: at 55.79% examples, 221954 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:20: EPOCH 24: training on 24174807 raw words (397164 effective words) took 1.8s, 226530 effective words/s\n",
      "INFO - 14:53:21: EPOCH 25 - PROGRESS: at 57.54% examples, 228785 words/s, in_qsize 2, out_qsize 3\n",
      "INFO - 14:53:21: EPOCH 25: training on 24174807 raw words (397560 effective words) took 1.7s, 230016 effective words/s\n",
      "INFO - 14:53:22: EPOCH 26 - PROGRESS: at 56.81% examples, 226364 words/s, in_qsize 13, out_qsize 20\n",
      "INFO - 14:53:23: EPOCH 26: training on 24174807 raw words (399204 effective words) took 1.7s, 230719 effective words/s\n",
      "INFO - 14:53:24: EPOCH 27 - PROGRESS: at 56.82% examples, 227375 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 14:53:25: EPOCH 27: training on 24174807 raw words (398214 effective words) took 1.7s, 229769 effective words/s\n",
      "INFO - 14:53:26: EPOCH 28 - PROGRESS: at 57.27% examples, 228710 words/s, in_qsize 1, out_qsize 3\n",
      "INFO - 14:53:26: EPOCH 28: training on 24174807 raw words (397973 effective words) took 1.7s, 229514 effective words/s\n",
      "INFO - 14:53:27: EPOCH 29 - PROGRESS: at 54.56% examples, 218022 words/s, in_qsize 8, out_qsize 8\n",
      "INFO - 14:53:28: EPOCH 29: training on 24174807 raw words (397282 effective words) took 1.8s, 220936 effective words/s\n",
      "INFO - 14:53:28: Word2Vec lifecycle event {'msg': 'training on 725244210 raw words (11951952 effective words) took 52.5s, 227495 effective words/s', 'datetime': '2023-05-20T14:53:28.778379', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'train'}\n",
      "/var/folders/dn/6362h3w12mqfb_jh4vg90vp40000gn/T/ipykernel_43812/1733578886.py:10: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "WARNING - 14:53:28: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.88 mins\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "w2v_model.train(sentences,\n",
    "                total_examples=w2v_model.corpus_count,\n",
    "                epochs=30,\n",
    "                report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:54:27: Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-05-20T14:54:27.804429', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'saving'}\n",
      "INFO - 14:54:27: not storing attribute cum_table\n",
      "INFO - 14:54:27: saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:54:31: loading Word2Vec object from word2vec.model\n",
      "INFO - 14:54:31: loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "INFO - 14:54:31: setting ignored attribute cum_table to None\n",
      "INFO - 14:54:31: Word2Vec lifecycle event {'fname': 'word2vec.model', 'datetime': '2023-05-20T14:54:31.385925', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'loaded'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(max_iter=1000, n_clusters=2, n_init=50, random_state=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(max_iter=1000, n_clusters=2, n_init=50, random_state=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(max_iter=1000, n_clusters=2, n_init=50, random_state=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv\n",
    "\n",
    "model = KMeans(n_clusters=2,\n",
    "               max_iter=1000,\n",
    "               random_state=True,\n",
    "               n_init=50)\n",
    "model.fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', 0.9932374954223633),\n",
       " ('G', 0.991351306438446),\n",
       " ('F', 0.9886654615402222),\n",
       " ('M', 0.9886630177497864),\n",
       " ('X', 0.983725368976593),\n",
       " ('K', 0.9813916683197021),\n",
       " ('H', 0.9813132286071777),\n",
       " ('D', 0.9808835983276367),\n",
       " ('L', 0.98053377866745),\n",
       " ('B', 0.9789462685585022)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
