{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from re import sub\n",
    "from time import time \n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'join'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/mwoj/Documents/GitHub/ZUM_NLP/k-means.ipynb Cell 2\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mwoj/Documents/GitHub/ZUM_NLP/k-means.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m file_model \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mmusk_clean.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mwoj/Documents/GitHub/ZUM_NLP/k-means.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sentences \u001b[39m=\u001b[39m file_model\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49mjoin(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mwoj/Documents/GitHub/ZUM_NLP/k-means.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sentences \u001b[39m=\u001b[39m Phraser(sentences)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:5487\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5480\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5481\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5482\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5483\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5484\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5485\u001b[0m ):\n\u001b[1;32m   5486\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5487\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'join'"
     ]
    }
   ],
   "source": [
    "file_model = pd.read_csv('musk_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 15:35:28: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2023-05-20T15:35:28.480117', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'created'}\n",
      "INFO - 15:35:28: collecting all words and their counts\n",
      "WARNING - 15:35:28: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "INFO - 15:35:28: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 15:35:29: PROGRESS: at sentence #50000, processed 18984775 words, keeping 76 word types\n",
      "INFO - 15:35:29: collected 76 word types from a corpus of 23355499 raw words and 61049 sentences\n",
      "INFO - 15:35:29: Creating a fresh vocabulary\n",
      "INFO - 15:35:29: Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 73 unique words (96.05% of original 76, drops 3)', 'datetime': '2023-05-20T15:35:29.605989', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 15:35:29: Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 23355494 word corpus (100.00% of original 23355499, drops 5)', 'datetime': '2023-05-20T15:35:29.606217', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 15:35:29: deleting the raw counts dictionary of 76 items\n",
      "INFO - 15:35:29: sample=1e-05 downsamples 48 most-common words\n",
      "INFO - 15:35:29: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 398638.617343787 word corpus (1.7%% of prior 23355494)', 'datetime': '2023-05-20T15:35:29.607287', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 15:35:29: estimated required memory for 73 words and 300 dimensions: 211700 bytes\n",
      "INFO - 15:35:29: resetting layer weights\n",
      "INFO - 15:35:29: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-05-20T15:35:29.608797', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 15:35:29: Word2Vec lifecycle event {'msg': 'training model with 7 workers on 73 vocabulary and 300 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4 shrink_windows=True', 'datetime': '2023-05-20T15:35:29.627826', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'train'}\n",
      "INFO - 15:35:30: EPOCH 0 - PROGRESS: at 57.72% examples, 230529 words/s, in_qsize 8, out_qsize 9\n",
      "INFO - 15:35:31: EPOCH 0: training on 23355499 raw words (399069 effective words) took 1.7s, 233040 effective words/s\n",
      "INFO - 15:35:32: EPOCH 1 - PROGRESS: at 58.89% examples, 235552 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:35:33: EPOCH 1: training on 23355499 raw words (399062 effective words) took 1.7s, 237997 effective words/s\n",
      "INFO - 15:35:34: EPOCH 2 - PROGRESS: at 58.23% examples, 232714 words/s, in_qsize 8, out_qsize 5\n",
      "INFO - 15:35:34: EPOCH 2: training on 23355499 raw words (399193 effective words) took 1.8s, 226367 effective words/s\n",
      "INFO - 15:35:35: EPOCH 3 - PROGRESS: at 58.66% examples, 236249 words/s, in_qsize 12, out_qsize 2\n",
      "INFO - 15:35:36: EPOCH 3: training on 23355499 raw words (399532 effective words) took 1.7s, 236300 effective words/s\n",
      "INFO - 15:35:37: EPOCH 4 - PROGRESS: at 58.38% examples, 233555 words/s, in_qsize 8, out_qsize 3\n",
      "INFO - 15:35:38: EPOCH 4: training on 23355499 raw words (398837 effective words) took 1.7s, 235987 effective words/s\n",
      "INFO - 15:35:39: EPOCH 5 - PROGRESS: at 58.88% examples, 235584 words/s, in_qsize 14, out_qsize 8\n",
      "INFO - 15:35:39: EPOCH 5: training on 23355499 raw words (398331 effective words) took 1.7s, 237212 effective words/s\n",
      "INFO - 15:35:40: EPOCH 6 - PROGRESS: at 57.99% examples, 231214 words/s, in_qsize 12, out_qsize 5\n",
      "INFO - 15:35:41: EPOCH 6: training on 23355499 raw words (398367 effective words) took 1.7s, 231167 effective words/s\n",
      "INFO - 15:35:42: EPOCH 7 - PROGRESS: at 58.97% examples, 236912 words/s, in_qsize 12, out_qsize 5\n",
      "INFO - 15:35:43: EPOCH 7: training on 23355499 raw words (398627 effective words) took 1.7s, 238531 effective words/s\n",
      "INFO - 15:35:44: EPOCH 8 - PROGRESS: at 57.54% examples, 230806 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:35:44: EPOCH 8: training on 23355499 raw words (398918 effective words) took 1.7s, 233167 effective words/s\n",
      "INFO - 15:35:45: EPOCH 9 - PROGRESS: at 57.72% examples, 230333 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:35:46: EPOCH 9: training on 23355499 raw words (398744 effective words) took 1.7s, 230935 effective words/s\n",
      "INFO - 15:35:47: EPOCH 10 - PROGRESS: at 58.88% examples, 235706 words/s, in_qsize 14, out_qsize 14\n",
      "INFO - 15:35:48: EPOCH 10: training on 23355499 raw words (398951 effective words) took 1.7s, 238883 effective words/s\n",
      "INFO - 15:35:49: EPOCH 11 - PROGRESS: at 59.18% examples, 238337 words/s, in_qsize 8, out_qsize 2\n",
      "INFO - 15:35:50: EPOCH 11: training on 23355499 raw words (398706 effective words) took 1.7s, 239099 effective words/s\n",
      "INFO - 15:35:51: EPOCH 12 - PROGRESS: at 57.92% examples, 231604 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:35:51: EPOCH 12: training on 23355499 raw words (398506 effective words) took 1.7s, 234387 effective words/s\n",
      "INFO - 15:35:52: EPOCH 13 - PROGRESS: at 57.10% examples, 228470 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:35:53: EPOCH 13: training on 23355499 raw words (398503 effective words) took 1.7s, 228287 effective words/s\n",
      "INFO - 15:35:54: EPOCH 14 - PROGRESS: at 58.79% examples, 236038 words/s, in_qsize 5, out_qsize 3\n",
      "INFO - 15:35:55: EPOCH 14: training on 23355499 raw words (398706 effective words) took 1.7s, 237596 effective words/s\n",
      "INFO - 15:35:56: EPOCH 15 - PROGRESS: at 58.89% examples, 237264 words/s, in_qsize 6, out_qsize 3\n",
      "INFO - 15:35:56: EPOCH 15: training on 23355499 raw words (399856 effective words) took 1.7s, 238463 effective words/s\n",
      "INFO - 15:35:57: EPOCH 16 - PROGRESS: at 58.83% examples, 235086 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:35:58: EPOCH 16: training on 23355499 raw words (398368 effective words) took 1.7s, 237191 effective words/s\n",
      "INFO - 15:35:59: EPOCH 17 - PROGRESS: at 59.02% examples, 237036 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:00: EPOCH 17: training on 23355499 raw words (399705 effective words) took 1.7s, 235013 effective words/s\n",
      "INFO - 15:36:01: EPOCH 18 - PROGRESS: at 59.03% examples, 235599 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:01: EPOCH 18: training on 23355499 raw words (397611 effective words) took 1.7s, 237871 effective words/s\n",
      "INFO - 15:36:02: EPOCH 19 - PROGRESS: at 58.49% examples, 234799 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:03: EPOCH 19: training on 23355499 raw words (399546 effective words) took 1.7s, 237897 effective words/s\n",
      "INFO - 15:36:04: EPOCH 20 - PROGRESS: at 58.48% examples, 232969 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:05: EPOCH 20: training on 23355499 raw words (398223 effective words) took 1.7s, 233372 effective words/s\n",
      "INFO - 15:36:06: EPOCH 21 - PROGRESS: at 57.27% examples, 227264 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:06: EPOCH 21: training on 23355499 raw words (398043 effective words) took 1.7s, 232845 effective words/s\n",
      "INFO - 15:36:07: EPOCH 22 - PROGRESS: at 57.68% examples, 230075 words/s, in_qsize 14, out_qsize 6\n",
      "INFO - 15:36:08: EPOCH 22: training on 23355499 raw words (398778 effective words) took 1.7s, 232785 effective words/s\n",
      "INFO - 15:36:09: EPOCH 23 - PROGRESS: at 57.44% examples, 228667 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:10: EPOCH 23: training on 23355499 raw words (398750 effective words) took 1.7s, 233894 effective words/s\n",
      "INFO - 15:36:11: EPOCH 24 - PROGRESS: at 58.99% examples, 235718 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:12: EPOCH 24: training on 23355499 raw words (398636 effective words) took 1.7s, 238284 effective words/s\n",
      "INFO - 15:36:13: EPOCH 25 - PROGRESS: at 57.59% examples, 229736 words/s, in_qsize 9, out_qsize 12\n",
      "INFO - 15:36:13: EPOCH 25: training on 23355499 raw words (398419 effective words) took 1.7s, 234923 effective words/s\n",
      "INFO - 15:36:14: EPOCH 26 - PROGRESS: at 58.61% examples, 232577 words/s, in_qsize 14, out_qsize 11\n",
      "INFO - 15:36:15: EPOCH 26: training on 23355499 raw words (397208 effective words) took 1.7s, 236104 effective words/s\n",
      "INFO - 15:36:16: EPOCH 27 - PROGRESS: at 58.87% examples, 236467 words/s, in_qsize 14, out_qsize 8\n",
      "INFO - 15:36:17: EPOCH 27: training on 23355499 raw words (398222 effective words) took 1.7s, 229237 effective words/s\n",
      "INFO - 15:36:18: EPOCH 28 - PROGRESS: at 58.49% examples, 234327 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 15:36:18: EPOCH 28: training on 23355499 raw words (398439 effective words) took 1.7s, 235866 effective words/s\n",
      "INFO - 15:36:19: EPOCH 29 - PROGRESS: at 58.68% examples, 233806 words/s, in_qsize 9, out_qsize 12\n",
      "INFO - 15:36:20: EPOCH 29: training on 23355499 raw words (398032 effective words) took 1.7s, 236143 effective words/s\n",
      "INFO - 15:36:20: Word2Vec lifecycle event {'msg': 'training on 700664970 raw words (11959888 effective words) took 51.0s, 234728 effective words/s', 'datetime': '2023-05-20T15:36:20.579645', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'train'}\n",
      "/var/folders/dn/6362h3w12mqfb_jh4vg90vp40000gn/T/ipykernel_44825/1733578886.py:10: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "WARNING - 15:36:20: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.85 mins\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "w2v_model.train(sentences,\n",
    "                total_examples=w2v_model.corpus_count,\n",
    "                epochs=30,\n",
    "                report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 15:36:21: Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-05-20T15:36:21.436715', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'saving'}\n",
      "INFO - 15:36:21: not storing attribute cum_table\n",
      "INFO - 15:36:21: saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 15:36:24: loading Word2Vec object from word2vec.model\n",
      "INFO - 15:36:24: loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "INFO - 15:36:24: setting ignored attribute cum_table to None\n",
      "INFO - 15:36:24: Word2Vec lifecycle event {'fname': 'word2vec.model', 'datetime': '2023-05-20T15:36:24.619527', 'gensim': '4.3.1', 'python': '3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \\n[Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'loaded'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(max_iter=1000, n_clusters=2, n_init=50, random_state=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(max_iter=1000, n_clusters=2, n_init=50, random_state=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(max_iter=1000, n_clusters=2, n_init=50, random_state=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv\n",
    "\n",
    "model = KMeans(n_clusters=2,\n",
    "               max_iter=1000,\n",
    "               random_state=True,\n",
    "               n_init=50)\n",
    "model.fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', 0.9917163252830505),\n",
       " ('N', 0.9905520081520081),\n",
       " ('M', 0.9858402609825134),\n",
       " ('G', 0.9855461120605469),\n",
       " ('X', 0.9844103455543518),\n",
       " ('Z', 0.9827008843421936),\n",
       " ('W', 0.9820296764373779),\n",
       " ('J', 0.9799992442131042),\n",
       " ('H', 0.9799615740776062),\n",
       " ('Q', 0.9798189997673035)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
