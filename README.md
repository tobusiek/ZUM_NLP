# PROJEKT ZALICZENIOWY
## Analiza sentymentu przy pomocy NLP

### Autorzy:
- MiÅ‚osz WÃ³jcik â€“ s26587
- Karol Manarczyk â€“ s26592
- Szymon JaÅ›kowski â€“ s26549

<br>

### Etap 1
**Branch:** *main* <br>
**Plik:** *scraper.ipynb* <br>
**Dane:** zebranie komentarzy i postÃ³w z reddita dotyczÄ…cych tagu *â€˜muskâ€™*, zapisane jako *musk.csv* <br>
**WstÄ™pne czyszczenie danych:** *cleaning_data.ipynb*, zapisane jako *musk_clean.csv*

**Branch:** *miszo* <br>
**Plik:** *cleaning_data_w2v_sentiment.ipynb* <br>
Pomoc przy czyszczeniu danych, przygotowanie bigramÃ³w i zastÄ…pienie nimi fraz w tekÅ›cie, budowa sÅ‚ownika przy pomocy Word2Vec (model rÃ³wnieÅ¼ zapisany w branchu), utworzenie klastrÃ³w przy pomocy metody k-mean, stworzenie pliku *sentiment_dictionary.csv* na potrzeby uczenia nienadzorowanego przy uÅ¼yciu tf-idf. 

**Plik:** *tfidf.ipynb* <br>
Przy uÅ¼yciu danych wyczyszczonych i sÅ‚ownika â€“ uczenie nienadzorowane i nadanie w ten sposÃ³b etykiet do wszystkich zdaÅ„ w zbiorze danych, pÃ³Åºniej uÅ¼ywane we wszystkich kolejnych etapach. Arbitralnie zadecydowana granica miÄ™dzy wiadomoÅ›ciami pozytywnymi i negatywnymi â€“ estymata sentymentu na poziomie -100, w przeciwnym wypadku dane byÅ‚yby bardzo przechylone w stronÄ™ komentarzy negatywnych â€“ ponad 90% do niecaÅ‚ych 10% pozytywnych.

<br>

### Etap 2
**Branch:** *Classic_machine_learning* <br>
**Plik:** *classic_algorithms.ipynb* <br>
Dane zostaÅ‚y wczytane i podzielone na dwa zbiory: treningowe i testowe. Oba zbiory zostaÅ‚y zapisane jako *'bag of words'*. Dopasowanie zostaÅ‚o dokonane na zbiorze treningowym. Wykorzystane zostaÅ‚y nastÄ™pujÄ…ce modele: naive Bayes, drzewo decyzyjne, las losowy, SVM. Najlepiej wypadÅ‚ model naiwnego Bayesa zarÃ³wno pod wzglÄ™dem dokÅ‚adnoÅ›ci, jak i wyniku f1. Zaraz za nim uplasowaÅ‚ siÄ™ las losowy. Na ostatnim miejscu znalazÅ‚o siÄ™ drzewo decyzyjne. Najlepszy z modeli osiÄ…gnÄ…Å‚ dokÅ‚adnoÅ›Ä‡ o wysokoÅ›ci 85,5% oraz wynik f1 w wysokoÅ›ci 0,85. Wyniki poszczegÃ³lnych modeli umieszczone zostaÅ‚y w pliku results/results_classic_ml.csv. W samym notatniku pod wywoÅ‚aniem kaÅ¼dego z modeli znajduje siÄ™: raport klasyfikacji, macierz pomyÅ‚ek oraz wykres zawierajÄ…cy krzywÄ… ROC.

<br>

### Etap 3
**Branch:** *basic_neural_networks* <br>
**Plik:** *basic_neural_networks.ipynb* <br>
Wczytanie oetykietowanych danych z pliku *labeled.csv*, ograniczenie zbioru (problemy z pamiÄ™ciÄ…) do wszystkich aktualnie posiadanych obserwacji z klasy o sentymencie negatywnym (5824 rekordy) i 10 tysiÄ™cy obserwacji z klasy o sentymencie pozytywnym. Rozdzielenie danych na zbiory treningowe, walidacyjne i testowe w proporcjach 70/20/10%. Wyliczenie wag klas ze wzglÄ™du na niezbalansowane dane - uwzglÄ™dnienie wag podczas uczenia. Wytrenowanie prostych modeli z warstwami gÄ™stymi, a nastÄ™pnie kilku z warstwami rekurencyjnymi. Modele z warstwami gÄ™stymi uczone na danych wczytanych jako *â€˜bag of wordsâ€™* - uÅ¼ycie CountVectorizer. Modele z rekurencyjnymi na danych w formacie potokenizowanej, z post-paddingiem. W obu przypadkach ograniczenie liczby sÅ‚Ã³w branych pod uwagÄ™ do 5 tysiÄ™cy. UÅ¼yty callback early stopping, monitorujÄ…cy minimalnÄ… wartoÅ›Ä‡ wyniku funkcji straty na zbiorze walidacyjnym. Najlepiej spisaÅ‚ siÄ™ model z dwukierunkowÄ… warstwÄ… rekurencyjnÄ… o wymiarze embeddingu rÃ³wnym 96 i rozmiarze wynikowym warstwy rÃ³wnym 128 ze zwiÄ™kszonym wskaÅºnikiem dropoutu - wynik: 93% dokÅ‚adnoÅ›ci oraz 96% peÅ‚noÅ›ci na zbiorze testowym. Modele zostaÅ‚y zapisane na branchu.

<br>

### Etap 4
**Branch:** *miszo* <br>
**Plik:** *bert.ipynb* <br>
Uczenie oparte na pretrenowanym modelu *distilbert-base-uncased*, z batchem wielkoÅ›ci 128 i ograniczeniem tekstu do 256 tokenÃ³w dÅ‚ugoÅ›ci, wyÅ¼sze wartoÅ›ci znaczÄ…co wydÅ‚uÅ¼aÅ‚y okres uczenia. Modelowi zajmowaÅ‚o ok. 8-10 minut na uczenie jednej epoki, wiÄ™c ograniczone zostaÅ‚o to do 5 epok, z widocznym szybkim przetrenowaniem modelu (rosnÄ…ca wartoÅ›Ä‡ funkcji straty na zbiorze walidacyjnym juÅ¼ od 2 epoki), a niepoprawiajÄ…cÄ… siÄ™ dokÅ‚adnoÅ›ciÄ…, od poczÄ…tku osiÄ…gajÄ…cÄ… ponad 90%. Test na zdaniu "I hate elon musk he is an idiot" zwrÃ³ciÅ‚ poprawnÄ… etykietÄ™ negatywnÄ…, co moÅ¼na uznaÄ‡ jako dodatkowy sukces w uczeniu modelu.

**Plik:** *zero_shot.ipynb* <br>
Drugi model jÄ™zykowy â€“ *bart-large-mnli*, z zadaniem zero-shot-classification, dodatkowo wykorzystany model flair - TextClassifier > en-sentiment. Po krÃ³tkim przygotowaniu danych do nauki, modelowi zajÄ™Å‚o ok. 90 minut przetworzenie caÅ‚oÅ›ci danych, a zwrÃ³cone wyniki byÅ‚y doÅ›Ä‡ niezadowalajÄ…ce, osiÄ…gajÄ…c 37% dokÅ‚adnoÅ›ci, co moÅ¼na rÃ³wnie dobrze odczytaÄ‡ jako 63% dokÅ‚adnoÅ›ci dla odwrÃ³conych etykiet ğŸ™‚ WiÄ…zaÅ‚o siÄ™ to prawdopodobnie z zaÅ‚oÅ¼onym odgÃ³rnie progiem >-100 oddzielajÄ…cym dwie etykiety w uczeniu nienadzorowanym, wiÄ™kszoÅ›Ä‡ etykiet powinna jednak byÄ‡ tam negatywna.

**Wnioski z etapu 4** â€“ Bert dostosowuje siÄ™ do nadanych etykiet duÅ¼o Å‚atwiej niÅ¼ drugi wykorzystany model, ktÃ³ry jednak nadal stara siÄ™ doÅ›Ä‡ subiektywnie podchodziÄ‡ do oceny sentymentu.
